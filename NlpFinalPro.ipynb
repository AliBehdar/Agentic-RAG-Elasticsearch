{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "GnCNykZ4qZ_C",
        "viiLxCPEqg2T",
        "wo8vV20z_cC9"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1c26622e604345c49a4fda5ba2cd5cd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_149c69f751384846a7a570745a5a1b69",
              "IPY_MODEL_fda4b11341754f98833a590bcfcd7436",
              "IPY_MODEL_a744d366266440c8b501b39404f389b5"
            ],
            "layout": "IPY_MODEL_4ec3daa28afe499e9bb22f58e85857e2"
          }
        },
        "149c69f751384846a7a570745a5a1b69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7fb81564ae5d4418a170e4e145a4eb58",
            "placeholder": "​",
            "style": "IPY_MODEL_85e1dada02094a65abdcefb34c2ba4e3",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "fda4b11341754f98833a590bcfcd7436": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc02e003553344fbba4c8f5331e6e0e8",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eef12a6ec0784ac7812ee6cf0bb52dae",
            "value": 2
          }
        },
        "a744d366266440c8b501b39404f389b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55df26b3c4654062af4addf8587aa7a7",
            "placeholder": "​",
            "style": "IPY_MODEL_b9d6abc791884dd381e0e442da571468",
            "value": " 2/2 [00:01&lt;00:00,  1.34it/s]"
          }
        },
        "4ec3daa28afe499e9bb22f58e85857e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fb81564ae5d4418a170e4e145a4eb58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85e1dada02094a65abdcefb34c2ba4e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc02e003553344fbba4c8f5331e6e0e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eef12a6ec0784ac7812ee6cf0bb52dae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "55df26b3c4654062af4addf8587aa7a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9d6abc791884dd381e0e442da571468": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# indexing"
      ],
      "metadata": {
        "id": "AB_j4Fcidx_E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## part 0"
      ],
      "metadata": {
        "id": "SPlKX4F0rfIC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install elasticsearch\n",
        "!pip install autoawq\n",
        "!pip install ragas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-rWAqIr-L9n",
        "outputId": "8ed5f809-fe11-479d-be9f-81606d48a286"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: elasticsearch in /usr/local/lib/python3.11/dist-packages (8.17.1)\n",
            "Requirement already satisfied: elastic-transport<9,>=8.15.1 in /usr/local/lib/python3.11/dist-packages (from elasticsearch) (8.17.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from elastic-transport<9,>=8.15.1->elasticsearch) (2.3.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from elastic-transport<9,>=8.15.1->elasticsearch) (2024.12.14)\n",
            "Requirement already satisfied: autoawq in /usr/local/lib/python3.11/dist-packages (0.2.8)\n",
            "Requirement already satisfied: torch>=2.5.1 in /usr/local/lib/python3.11/dist-packages (from autoawq) (2.5.1+cu124)\n",
            "Requirement already satisfied: triton in /usr/local/lib/python3.11/dist-packages (from autoawq) (3.1.0)\n",
            "Requirement already satisfied: transformers<=4.47.1,>=4.45.0 in /usr/local/lib/python3.11/dist-packages (from autoawq) (4.47.1)\n",
            "Requirement already satisfied: tokenizers>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from autoawq) (0.21.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from autoawq) (4.12.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (from autoawq) (1.2.1)\n",
            "Requirement already satisfied: datasets>=2.20 in /usr/local/lib/python3.11/dist-packages (from autoawq) (3.2.0)\n",
            "Requirement already satisfied: zstandard in /usr/local/lib/python3.11/dist-packages (from autoawq) (0.23.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.26.5 in /usr/local/lib/python3.11/dist-packages (from autoawq) (0.27.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.20->autoawq) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.20->autoawq) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.20->autoawq) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.20->autoawq) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=2.20->autoawq) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.20->autoawq) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.20->autoawq) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=2.20->autoawq) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.20->autoawq) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.20->autoawq) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.20->autoawq) (3.11.11)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets>=2.20->autoawq) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.20->autoawq) (6.0.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->autoawq) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->autoawq) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->autoawq) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->autoawq) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->autoawq) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->autoawq) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->autoawq) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->autoawq) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->autoawq) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->autoawq) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->autoawq) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->autoawq) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->autoawq) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->autoawq) (12.4.127)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->autoawq) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.5.1->autoawq) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<=4.47.1,>=4.45.0->autoawq) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<=4.47.1,>=4.45.0->autoawq) (0.5.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate->autoawq) (5.9.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.20->autoawq) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.20->autoawq) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.20->autoawq) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.20->autoawq) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.20->autoawq) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.20->autoawq) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.20->autoawq) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.20->autoawq) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.20->autoawq) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.20->autoawq) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.20->autoawq) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.5.1->autoawq) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.20->autoawq) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.20->autoawq) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.20->autoawq) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.20->autoawq) (1.17.0)\n",
            "Requirement already satisfied: ragas in /usr/local/lib/python3.11/dist-packages (0.2.13)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ragas) (1.26.4)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (from ragas) (3.2.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from ragas) (0.8.0)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (from ragas) (0.3.16)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.11/dist-packages (from ragas) (0.3.33)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (from ragas) (0.3.16)\n",
            "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.11/dist-packages (from ragas) (0.3.3)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ragas) (1.6.0)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.11/dist-packages (from ragas) (1.4.4)\n",
            "Requirement already satisfied: pydantic>=2 in /usr/local/lib/python3.11/dist-packages (from ragas) (2.10.6)\n",
            "Requirement already satisfied: openai>1 in /usr/local/lib/python3.11/dist-packages (from ragas) (1.59.9)\n",
            "Requirement already satisfied: diskcache>=5.6.3 in /usr/local/lib/python3.11/dist-packages (from ragas) (5.6.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai>1->ragas) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>1->ragas) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai>1->ragas) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>1->ragas) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>1->ragas) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai>1->ragas) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai>1->ragas) (4.12.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2->ragas) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2->ragas) (2.27.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets->ragas) (3.17.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->ragas) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets->ragas) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets->ragas) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets->ragas) (2.32.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets->ragas) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets->ragas) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets->ragas) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets->ragas) (3.11.11)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets->ragas) (0.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets->ragas) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets->ragas) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain->ragas) (2.0.37)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain->ragas) (0.3.5)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain->ragas) (0.3.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain->ragas) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core->ragas) (1.33)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community->ragas) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community->ragas) (0.4.0)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community->ragas) (2.7.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->ragas) (2024.11.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->ragas) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->ragas) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->ragas) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->ragas) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->ragas) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->ragas) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->ragas) (1.18.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai>1->ragas) (3.10)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas) (0.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai>1->ragas) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai>1->ragas) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>1->ragas) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core->ragas) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain->ragas) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain->ragas) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain->ragas) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community->ragas) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->ragas) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->ragas) (2.3.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain->ragas) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->ragas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->ragas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->ragas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->ragas) (1.17.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->ragas) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvAteZJGdrAr",
        "outputId": "83df4570-71b9-40fd-8669-9efe3604a341"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "from elasticsearch import Elasticsearch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "from elasticsearch.helpers import bulk\n",
        "import json\n"
      ],
      "metadata": {
        "id": "DgR5UfDB-JOu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "es = Elasticsearch(f'https://sour-pugs-wash.loca.lt',timeout=60, max_retries=3, retry_on_timeout=True)\n",
        "\n",
        "try:\n",
        "    client_info = es.info()\n",
        "    print('Connected to Elasticsearch!')\n",
        "    pprint(client_info.body)\n",
        "except Exception as e:\n",
        "    print(f\"Connection failed: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARDf9EGK9-Eq",
        "outputId": "5a014693-da38-4e87-cb94-be9031375447"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-21041b070a68>:1: DeprecationWarning: The 'timeout' parameter is deprecated in favor of 'request_timeout'\n",
            "  es = Elasticsearch(f'https://sour-pugs-wash.loca.lt',timeout=60, max_retries=3, retry_on_timeout=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connected to Elasticsearch!\n",
            "{'cluster_name': 'docker-cluster',\n",
            " 'cluster_uuid': '_g8en_PbS5a2cPP2N9LEzQ',\n",
            " 'name': '49a61ee328aa',\n",
            " 'tagline': 'You Know, for Search',\n",
            " 'version': {'build_date': '2024-08-05T10:05:34.233336849Z',\n",
            "             'build_flavor': 'default',\n",
            "             'build_hash': '1a77947f34deddb41af25e6f0ddb8e830159c179',\n",
            "             'build_snapshot': False,\n",
            "             'build_type': 'docker',\n",
            "             'lucene_version': '9.11.1',\n",
            "             'minimum_index_compatibility_version': '7.0.0',\n",
            "             'minimum_wire_compatibility_version': '7.17.0',\n",
            "             'number': '8.15.0'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## part 1"
      ],
      "metadata": {
        "id": "q7ehBzeqqV4k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "index_name = \"dataset_1\"\n",
        "MODEL_NAME = 'paraphrase-multilingual-mpnet-base-v2'\n",
        "EMBEDDING_DIM = 768\n",
        "\n",
        "settings = {\n",
        "    \"settings\": {\n",
        "        \"analysis\": {\n",
        "            \"char_filter\": {\n",
        "                \"zero_width_spaces\": {\n",
        "                    \"type\": \"mapping\",\n",
        "                    \"mappings\": [\"\\\\u200C=>\\\\u0020\"]\n",
        "                }\n",
        "            },\n",
        "            \"filter\": {\n",
        "                \"persian_stop\": {\"type\": \"stop\",\"stopwords\": \"_persian_\"}\n",
        "            },\n",
        "            \"analyzer\": {\n",
        "                \"rebuilt_persian\": {\n",
        "                    \"tokenizer\": \"standard\",\n",
        "                    \"char_filter\": [\"zero_width_spaces\"],\n",
        "                    \"filter\": [\n",
        "                        \"lowercase\",\n",
        "                        \"decimal_digit\",\n",
        "                        \"arabic_normalization\",\n",
        "                        \"persian_normalization\",\n",
        "                        \"persian_stop\"\n",
        "                    ]\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"mappings\": {\n",
        "        \"properties\": {\n",
        "            \"نام\": {\"type\": \"text\",\"analyzer\": \"rebuilt_persian\"},\n",
        "            \"توضیحات\": {\"type\": \"text\",\"analyzer\": \"rebuilt_persian\"},\n",
        "            \"ادرس\": {\"type\": \"text\",\"analyzer\": \"rebuilt_persian\"},\n",
        "            \"بهترین زمان\": {\"type\": \"keyword\"},\n",
        "            \"نوع\": {\"type\": \"keyword\"},\n",
        "            \"تاریخچه\": {\"type\": \"text\",\"analyzer\": \"rebuilt_persian\"},\n",
        "            \"embedding\":{\n",
        "                \"type\":\"dense_vector\",\n",
        "                \"dims\":EMBEDDING_DIM,\n",
        "                \"index\":True,\n",
        "                \"similarity\":\"cosine\"\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "es.indices.delete(index=index_name, ignore_unavailable=True)\n",
        "es.options(ignore_status=400).indices.create(index=index_name, body=settings)\n",
        "print(f\"Index '{index_name}' created successfully!\")\n",
        "\n",
        "model=SentenceTransformer(MODEL_NAME)\n",
        "\n",
        "with open(\"/content/drive/MyDrive/NLPPDARA/output.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "def enhance_documents():\n",
        "    for doc in data:\n",
        "\n",
        "        context = \" \".join([\n",
        "            doc.get(\"نام\", \"\"),\n",
        "            doc.get(\"توضیحات\", \"\"),\n",
        "            doc.get(\"ادرس\", \"\"),\n",
        "            doc.get(\"بهترین زمان\", \"\"),\n",
        "            doc.get(\"تاریخچه\", \"\"),\n",
        "            doc.get(\"نوع\", \"\")\n",
        "        ])\n",
        "        doc[\"embedding\"] = model.encode(\n",
        "            context,\n",
        "            convert_to_tensor=False,\n",
        "            show_progress_bar=False\n",
        "        ).tolist()\n",
        "\n",
        "        yield doc\n",
        "\n",
        "actions = [\n",
        "    {\n",
        "        \"_op_type\": \"index\",\n",
        "        \"_index\": index_name,\n",
        "        \"_id\": doc[\"id\"],\n",
        "        \"_source\": doc\n",
        "    } for doc in enhance_documents()\n",
        "]\n",
        "\n",
        "success, _ = bulk(es, actions)\n",
        "print(f\"تعداد اسناد وارد شده: {success}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8H-qaLxIdwP5",
        "outputId": "4357e292-7197-4d94-8493-2653e9cbc86e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index 'dataset_1' created successfully!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "تعداد اسناد وارد شده: 30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_name2 = \"dataset_2\"\n",
        "settings2 = {\n",
        "    \"settings\": {\n",
        "        \"analysis\": {\n",
        "            \"char_filter\": {\n",
        "                \"zero_width_spaces\": {\n",
        "                    \"type\": \"mapping\",\n",
        "                    \"mappings\": [\"\\\\u200C=>\\\\u0020\"]\n",
        "                }\n",
        "            },\n",
        "            \"filter\": {\n",
        "                \"persian_stop\": {\n",
        "                    \"type\": \"stop\",\n",
        "                    \"stopwords\": \"_persian_\"\n",
        "                }\n",
        "            },\n",
        "            \"analyzer\": {\n",
        "                \"rebuilt_persian\": {\n",
        "                    \"tokenizer\": \"standard\",\n",
        "                    \"char_filter\": [\"zero_width_spaces\"],\n",
        "                    \"filter\": [\n",
        "                        \"lowercase\",\n",
        "                        \"decimal_digit\",\n",
        "                        \"arabic_normalization\",\n",
        "                        \"persian_normalization\",\n",
        "                        \"persian_stop\"\n",
        "                    ]\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"mappings\": {\n",
        "        \"properties\": {\n",
        "            \"question\": {\n",
        "                \"type\": \"text\",\n",
        "                \"analyzer\": \"rebuilt_persian\"\n",
        "            },\n",
        "            \"answer\": {\n",
        "                \"type\": \"text\",\n",
        "                \"analyzer\": \"rebuilt_persian\"\n",
        "                },\n",
        "            \"embedding\":{\n",
        "                \"type\":\"dense_vector\",\n",
        "                \"dims\":EMBEDDING_DIM,\n",
        "                \"index\":True,\n",
        "                \"similarity\":\"cosine\"\n",
        "            }\n",
        "    }\n",
        "\n",
        "}\n",
        "}\n",
        "es.indices.delete(index=index_name2, ignore_unavailable=True)\n",
        "es.options(ignore_status=400).indices.create(index=index_name2, body=settings2)\n",
        "print(f\"Index '{index_name2}' created successfully!\")\n",
        "\n",
        "\n",
        "with open(\"/content/drive/MyDrive/NLPPDARA/output1.2.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    data2 = json.load(f)\n",
        "\n",
        "def enhance_documentsQ():\n",
        "    for doc in data2:\n",
        "\n",
        "        context = \" \".join([\n",
        "            doc.get(\"question\", \"\"),\n",
        "            doc.get(\"answer\", \"\"),\n",
        "        ])\n",
        "\n",
        "        doc[\"embedding\"] = model.encode(context,convert_to_tensor=False,show_progress_bar=False).tolist()\n",
        "\n",
        "        yield doc\n",
        "\n",
        "actions = [\n",
        "    {\n",
        "        \"_op_type\": \"index\",\n",
        "        \"_index\": index_name2,\n",
        "        \"_id\": doc[\"id\"],\n",
        "        \"_source\": doc\n",
        "    } for doc in enhance_documentsQ()\n",
        "]\n",
        "\n",
        "success, _ = bulk(es, actions,request_timeout=120)\n",
        "print(f\"تعداد اسناد وارد شده: {success}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNiGaJlTmX8X",
        "outputId": "44dab6b0-307e-47c3-a9f3-d37ae65afa1b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index 'dataset_2' created successfully!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-9ebd6a9a0188>:81: DeprecationWarning: Passing transport options in the API method is deprecated. Use 'Elasticsearch.options()' instead.\n",
            "  success, _ = bulk(es, actions,request_timeout=120)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "تعداد اسناد وارد شده: 150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## part2"
      ],
      "metadata": {
        "id": "GnCNykZ4qZ_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_name3 = \"dataset_3\"\n",
        "settings3 = {\n",
        "    \"settings\": {\n",
        "        \"analysis\": {\n",
        "            \"char_filter\": {\n",
        "                \"zero_width_spaces\": {\n",
        "                    \"type\": \"mapping\",\n",
        "                    \"mappings\": [\"\\\\u200C=>\\\\u0020\"]\n",
        "                }\n",
        "            },\n",
        "            \"filter\": {\n",
        "                \"persian_stop\": {\n",
        "                    \"type\": \"stop\",\n",
        "                    \"stopwords\": \"_persian_\"\n",
        "                }\n",
        "            },\n",
        "            \"analyzer\": {\n",
        "                \"rebuilt_persian\": {\n",
        "                    \"tokenizer\": \"standard\",\n",
        "                    \"char_filter\": [\"zero_width_spaces\"],\n",
        "                    \"filter\": [\n",
        "                        \"lowercase\",\n",
        "                        \"decimal_digit\",\n",
        "                        \"arabic_normalization\",\n",
        "                        \"persian_normalization\",\n",
        "                        \"persian_stop\"\n",
        "                    ]\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"mappings\": {\n",
        "        \"properties\": {\n",
        "            \"نام\": {\n",
        "                \"type\": \"text\",\n",
        "                \"analyzer\": \"rebuilt_persian\"\n",
        "            },\n",
        "            \"توضیحات\": {\n",
        "                \"type\": \"text\",\n",
        "                \"analyzer\": \"rebuilt_persian\"\n",
        "            },\n",
        "            \"embedding\": {\n",
        "                \"type\": \"dense_vector\",\n",
        "                \"dims\": EMBEDDING_DIM,\n",
        "                \"index\": True,\n",
        "                \"similarity\": \"cosine\"\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "es.indices.delete(index=index_name3, ignore_unavailable=True)\n",
        "es.indices.create(index=index_name3, body=settings3)\n",
        "print(f\"Index '{index_name3}' created successfully!\")\n",
        "\n",
        "\n",
        "with open(\"/content/drive/MyDrive/NLPPDARA/output2.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    data3 = json.load(f)\n",
        "for doc in data3:\n",
        "    if \"نام \" in doc:\n",
        "        doc[\"نام\"] = doc.pop(\"نام \")\n",
        "\n",
        "\n",
        "def enhance_documents():\n",
        "\n",
        "    for doc in data3:\n",
        "\n",
        "        context = \" \".join([\n",
        "            doc.get(\"نام\", \"\"),\n",
        "            doc.get(\"توضیحات\", \"\")\n",
        "        ])\n",
        "\n",
        "        doc[\"embedding\"] = model.encode(context, convert_to_tensor=False, show_progress_bar=False).tolist()\n",
        "        yield doc\n",
        "\n",
        "actions = [\n",
        "    {\n",
        "        \"_op_type\": \"index\",\n",
        "        \"_index\": index_name3,\n",
        "        \"_id\": doc[\"id\"],\n",
        "        \"_source\": doc\n",
        "    }\n",
        "    for doc in enhance_documents()\n",
        "]\n",
        "\n",
        "success, _ = bulk(es, actions)\n",
        "print(f\"Number of documents indexed: {success}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PU84mrwigv1V",
        "outputId": "20fef3f3-d3c3-4d88-e493-771c956de031"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index 'dataset_3' created successfully!\n",
            "Number of documents indexed: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_name4 = \"dataset_4\"\n",
        "es.indices.delete(index=index_name4, ignore_unavailable=True)\n",
        "es.options(ignore_status=400).indices.create(index=index_name4, body=settings2)\n",
        "print(f\"Index '{index_name4}' created successfully!\")\n",
        "\n",
        "with open(\"/content/drive/MyDrive/NLPPDARA/output2.1.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    data4 = json.load(f)\n",
        "\n",
        "def enhance_documents():\n",
        "    for doc in data4:\n",
        "\n",
        "        context = \" \".join([\n",
        "            doc.get(\"question\", \"\"),\n",
        "            doc.get(\"answer\", \"\"),\n",
        "        ])\n",
        "\n",
        "        doc[\"embedding\"] = model.encode(context,convert_to_tensor=False,show_progress_bar=False).tolist()\n",
        "\n",
        "        yield doc\n",
        "\n",
        "actions = [\n",
        "    {\n",
        "        \"_op_type\": \"index\",\n",
        "        \"_index\": index_name4,\n",
        "        \"_id\": doc[\"id\"],\n",
        "        \"_source\": doc\n",
        "    } for doc in enhance_documents()\n",
        "]\n",
        "\n",
        "success, _ = bulk(es, actions)\n",
        "print(f\"تعداد اسناد وارد شده: {success}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiEMhX7im2io",
        "outputId": "f2811361-1dcd-455f-bbff-5dfc6fbfb02e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index 'dataset_4' created successfully!\n",
            "تعداد اسناد وارد شده: 151\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## part 3"
      ],
      "metadata": {
        "id": "viiLxCPEqg2T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "index_name5 = \"dataset_5\"\n",
        "settings5 = {\n",
        "    \"settings\": {\n",
        "        \"analysis\": {\n",
        "            \"char_filter\": {\n",
        "                \"zero_width_spaces\": {\n",
        "                    \"type\": \"mapping\",\n",
        "                    \"mappings\": [\"\\\\u200C=>\\\\u0020\"]\n",
        "                }\n",
        "            },\n",
        "            \"filter\": {\n",
        "                \"persian_stop\": {\n",
        "                    \"type\": \"stop\",\n",
        "                    \"stopwords\": \"_persian_\"\n",
        "                }\n",
        "            },\n",
        "            \"analyzer\": {\n",
        "                \"rebuilt_persian\": {\n",
        "                    \"tokenizer\": \"standard\",\n",
        "                    \"char_filter\": [\"zero_width_spaces\"],\n",
        "                    \"filter\": [\n",
        "                        \"lowercase\",\n",
        "                        \"decimal_digit\",\n",
        "                        \"arabic_normalization\",\n",
        "                        \"persian_normalization\",\n",
        "                        \"persian_stop\"\n",
        "                    ]\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"mappings\": {\n",
        "        \"properties\": {\n",
        "            \"نام شهر\": {\"type\": \"text\",\"analyzer\": \"rebuilt_persian\"},\n",
        "            \"معرفی\": {\"type\": \"text\",\"analyzer\": \"rebuilt_persian\"},\n",
        "            \"آب و هوا\": {\"type\": \"text\",\"analyzer\": \"rebuilt_persian\"},\n",
        "            \"دیدنی ها\": {\"type\": \"text\",\"analyzer\": \"rebuilt_persian\"},\n",
        "            \"سوغات\": {\"type\": \"text\",\"analyzer\": \"rebuilt_persian\"},\n",
        "            \"غذاهای محلی \": {\"type\": \"text\",\"analyzer\": \"rebuilt_persian\"},\n",
        "            \"اقامت \": {\"type\": \"text\",\"analyzer\": \"rebuilt_persian\"},\n",
        "            \"رستوران ها\": {\"type\": \"text\",\"analyzer\": \"rebuilt_persian\"},\n",
        "            \"حمل‌ و نقل عمومی\": {\"type\": \"text\",\"analyzer\": \"rebuilt_persian\"},\n",
        "            \"آداب و رسوم مردم\": {\"type\": \"text\",\"analyzer\": \"rebuilt_persian\"},\n",
        "            \"راهنمای سفر\": {\"type\": \"text\",\"analyzer\": \"rebuilt_persian\"},\n",
        "            \"embedding\":{\n",
        "                \"type\":\"dense_vector\",\n",
        "                \"dims\":EMBEDDING_DIM,\n",
        "                \"index\":True,\n",
        "                \"similarity\":\"cosine\"\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "es.indices.delete(index=index_name5, ignore_unavailable=True)\n",
        "es.options(ignore_status=400).indices.create(index=index_name5, body=settings5)\n",
        "print(f\"Index '{index_name5}' created successfully!\")\n",
        "\n",
        "with open(\"/content/drive/MyDrive/NLPPDARA/output3.2.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    data5 = json.load(f)\n",
        "\n",
        "def enhance_documents():\n",
        "    for doc in data5:\n",
        "        context = \" \".join([\n",
        "            doc.get(\"نام شهر\") or \"\",\n",
        "            doc.get(\"معرفی\") or \"\",\n",
        "            doc.get(\"آب و هوا\") or \"\",\n",
        "            doc.get(\"دیدنی ها\") or \"\",\n",
        "            doc.get(\"سوغات \") or \"\",\n",
        "            doc.get(\"غذاهای محلی \") or \"\",\n",
        "            doc.get(\"اقامت\") or \"\",\n",
        "            doc.get(\"رستوران ها\") or \"\",\n",
        "            doc.get(\"حمل‌ و نقل عمومی\") or \"\",\n",
        "            doc.get(\"آداب و رسوم مردم \") or \"\",\n",
        "            doc.get(\"راهنمای سفر\") or \"\"\n",
        "        ])\n",
        "\n",
        "        doc[\"embedding\"] = model.encode(context, convert_to_tensor=False, show_progress_bar=False).tolist()\n",
        "\n",
        "        yield doc\n",
        "\n",
        "actions = [\n",
        "    {\n",
        "        \"_op_type\": \"index\",\n",
        "        \"_index\": index_name5,\n",
        "        \"_id\": doc[\"id\"],\n",
        "        \"_source\": doc\n",
        "    } for doc in enhance_documents()\n",
        "]\n",
        "\n",
        "success, _ = bulk(es, actions)\n",
        "print(f\"تعداد اسناد وارد شده: {success}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kLq3o0giDpA",
        "outputId": "4a590dc2-91a2-40b8-81ac-8af69f0a65c2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index 'dataset_5' created successfully!\n",
            "تعداد اسناد وارد شده: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-hoT1AALHznb"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_name6 = \"dataset_6\"\n",
        "es.indices.delete(index=index_name6, ignore_unavailable=True)\n",
        "es.options(ignore_status=400).indices.create(index=index_name6, body=settings2)\n",
        "print(f\"Index '{index_name6}' created successfully!\")\n",
        "\n",
        "with open(\"/content/drive/MyDrive/NLPPDARA/STANIRA1.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    data6 = json.load(f)\n",
        "\n",
        "def enhance_documents():\n",
        "    for doc in data6:\n",
        "\n",
        "        context = \" \".join([\n",
        "            doc.get(\"question\", \"\"),\n",
        "            doc.get(\"answer\", \"\"),\n",
        "        ])\n",
        "        doc[\"embedding\"] = model.encode(context,convert_to_tensor=False,show_progress_bar=False).tolist()\n",
        "\n",
        "        yield doc\n",
        "\n",
        "actions = [\n",
        "    {\n",
        "        \"_op_type\": \"index\",\n",
        "        \"_index\": index_name6,\n",
        "        \"_id\": doc[\"id\"],\n",
        "        \"_source\": doc\n",
        "    } for doc in enhance_documents()\n",
        "]\n",
        "\n",
        "success, _ = bulk(es, actions,request_timeout=120)\n",
        "print(f\"تعداد اسناد وارد شده: {success}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1H_Hv5M0Yz5y",
        "outputId": "a9ad7433-931a-4331-e486-6258b5421f7a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index 'dataset_6' created successfully!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-94bee684e0e3>:29: DeprecationWarning: Passing transport options in the API method is deprecated. Use 'Elasticsearch.options()' instead.\n",
            "  success, _ = bulk(es, actions,request_timeout=120)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "تعداد اسناد وارد شده: 287\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_name7 = \"dataset_7\"\n",
        "es.indices.delete(index=index_name7, ignore_unavailable=True)\n",
        "es.options(ignore_status=400).indices.create(index=index_name7, body=settings2)\n",
        "print(f\"Index '{index_name7}' created successfully!\")\n",
        "\n",
        "with open(\"/content/drive/MyDrive/NLPPDARA/output3.3.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    data7 = json.load(f)\n",
        "\n",
        "def enhance_documents():\n",
        "    for doc in data7:\n",
        "\n",
        "        context = \" \".join([\n",
        "            doc.get(\"question\", \"\"),\n",
        "            doc.get(\"answer\", \"\"),\n",
        "        ])\n",
        "        doc[\"embedding\"] = model.encode(context,convert_to_tensor=False,show_progress_bar=False).tolist()\n",
        "\n",
        "        yield doc\n",
        "\n",
        "actions = [\n",
        "    {\n",
        "        \"_op_type\": \"index\",\n",
        "        \"_index\": index_name7,\n",
        "        \"_id\": doc[\"id\"],\n",
        "        \"_source\": doc\n",
        "    } for doc in enhance_documents()\n",
        "]\n",
        "\n",
        "success, _ = bulk(es, actions,request_timeout=240)\n",
        "print(f\"تعداد اسناد وارد شده: {success}\")"
      ],
      "metadata": {
        "id": "65FglViInCl4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa4e1cd2-0677-411e-e0a0-fde0d00f6427"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index 'dataset_7' created successfully!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-a40466d07510>:29: DeprecationWarning: Passing transport options in the API method is deprecated. Use 'Elasticsearch.options()' instead.\n",
            "  success, _ = bulk(es, actions,request_timeout=240)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "تعداد اسناد وارد شده: 799\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Query"
      ],
      "metadata": {
        "id": "wo8vV20z_cC9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def elastic_search1(query: str) -> str:\n",
        "    index_name = f\"dataset_1\"\n",
        "    query_embedding = model.encode(query, convert_to_tensor=False).tolist()\n",
        "\n",
        "\n",
        "    search_query = {\n",
        "        \"function_score\":{\n",
        "            \"query\":{\"multi_match\":{\"query\":query,\"fields\":[\"نام\", \"توضیحات\", \"ادرس\", \"بهترین زمان\", \"نوع\", \"تاریخچه\"]}},\n",
        "            \"functions\":[{\"script_score\": {\"script\": {\"source\": \"cosineSimilarity(params.query_vector, 'embedding') + 1.0\",\"params\": {\"query_vector\": query_embedding}}}}],\n",
        "            \"boost_mode\":\"multiply\",\n",
        "            \"score_mode\":\"sum\"}\n",
        "        }\n",
        "    response = es.search(\n",
        "        index=index_name,\n",
        "        body={\n",
        "            \"size\": 2,\n",
        "            \"query\": search_query,\n",
        "            \"_source\": [\"نام\", \"توضیحات\", \"ادرس\", \"بهترین زمان\", \"نوع\", \"تاریخچه\"]\n",
        "        }\n",
        "    )\n",
        "\n",
        "    if not response['hits']['hits']:\n",
        "        return \"نتیجهای یافت نشد\"\n",
        "\n",
        "\n",
        "\n",
        "    formatted_results = \"\"\n",
        "\n",
        "    for i, hit in enumerate(response['hits']['hits'], start=1):\n",
        "        result = hit['_source']\n",
        "        formatted_results += (\n",
        "            f\"نام: {result.get('نام', '--')}\\n\"\n",
        "            f\"توضیحات: {result.get('توضیحات', '--')}\\n\"\n",
        "            f\"آدرس: {result.get('ادرس', '--')}\\n\"\n",
        "            f\"نوع: {result.get('نوع', '--')}\\n\"\n",
        "            f\"بهترین زمان بازدید: {result.get('بهترین زمان', '--')}\\n\"\n",
        "            f\"تاریخچه: {result.get('تاریخچه', '--')}\\n\")\n",
        "\n",
        "    return formatted_results\n"
      ],
      "metadata": {
        "id": "R6FzSYaL-30y"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def elastic_search2(query: str) -> str:\n",
        "    index_name = f\"dataset_2\"\n",
        "    query_embedding = model.encode(query, convert_to_tensor=False).tolist()\n",
        "\n",
        "    search_query = {\n",
        "        \"function_score\":{\n",
        "            \"query\": {\"multi_match\": {\"query\":query,\"fields\":[\"question\", \"answer\"]}},\n",
        "            \"functions\":[{\"script_score\": {\"script\": {\"source\": \"cosineSimilarity(params.query_vector, 'embedding') + 1.0\",\"params\": {\"query_vector\": query_embedding}}}}],\n",
        "            \"boost_mode\":\"multiply\",\n",
        "            \"score_mode\":\"sum\"\n",
        "    }\n",
        "    }\n",
        "\n",
        "\n",
        "    response = es.search(\n",
        "        index=index_name,\n",
        "        body={\n",
        "            \"size\": 3,\n",
        "            \"query\": search_query,\n",
        "            \"_source\": [\"question\", \"answer\"]\n",
        "        }\n",
        "    )\n",
        "\n",
        "    if not response['hits']['hits']:\n",
        "        return \"نتیجهای یافت نشد\"\n",
        "\n",
        "    formatted_results = \"\"\n",
        "    for i, hit in enumerate(response['hits']['hits'], start=1):\n",
        "        result = hit['_source']\n",
        "        formatted_results += (\n",
        "            f\"Match {i}:\\n\"\n",
        "            f\"question: {result.get('question', '--')}\\n\"\n",
        "            f\"answer: {result.get('answer', '--')}\\n\\n\"\n",
        "        )\n",
        "\n",
        "    return formatted_results"
      ],
      "metadata": {
        "id": "6unNcU2Z_C2s"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def elastic_search3(query: str) -> str:\n",
        "    index_name = f\"dataset_3\"\n",
        "    query_embedding = model.encode(query, convert_to_tensor=False).tolist()\n",
        "\n",
        "    search_query = {\n",
        "        \"function_score\": {\n",
        "            \"query\": {\n",
        "                \"multi_match\": {\n",
        "                    \"query\": query,\n",
        "                    \"fields\": [\"نام^2\", \"توضیحات\"]\n",
        "                }\n",
        "            },\n",
        "            \"functions\": [\n",
        "                {\n",
        "                    \"script_score\": {\n",
        "                        \"script\": {\n",
        "                            \"source\": \"cosineSimilarity(params.query_vector, 'embedding') + 1.0\",\n",
        "                            \"params\": {\"query_vector\": query_embedding}\n",
        "                        }\n",
        "                    }\n",
        "                }\n",
        "            ],\n",
        "            \"boost_mode\": \"multiply\",\n",
        "            \"score_mode\": \"sum\"\n",
        "        }\n",
        "    }\n",
        "\n",
        "    response = es.search(\n",
        "        index=index_name,\n",
        "        body={\n",
        "            \"size\": 2,\n",
        "            \"query\": search_query,\n",
        "            \"_source\": [\"نام\", \"توضیحات\"]\n",
        "        }\n",
        "    )\n",
        "\n",
        "    if not response['hits']['hits']:\n",
        "        return \"نتیجه ای یافت نشد\"\n",
        "\n",
        "    formatted_results = \"\"\n",
        "    for i, hit in enumerate(response['hits']['hits'], start=1):\n",
        "        result = hit['_source']\n",
        "        formatted_results += (\n",
        "            f\"Match {i}:\\n\"\n",
        "            f\"نام: {result.get('نام', '--')}\\n\"\n",
        "            f\"توضیحات: {result.get('توضیحات', '--')}\\n\\n\"\n",
        "        )\n",
        "    return formatted_results\n"
      ],
      "metadata": {
        "id": "XDpU7lQF_Lgb"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def elastic_search4(query: str) -> str:\n",
        "    index_name = f\"dataset_4\"\n",
        "    query_embedding = model.encode(query, convert_to_tensor=False).tolist()\n",
        "\n",
        "    search_query = {\n",
        "        \"function_score\":{\n",
        "            \"query\": {\"multi_match\": {\"query\":query,\"fields\":[\"question\", \"answer\"]}},\n",
        "            \"functions\":[{\"script_score\": {\"script\": {\"source\": \"cosineSimilarity(params.query_vector, 'embedding') + 1.0\",\"params\": {\"query_vector\": query_embedding}}}}],\n",
        "            \"boost_mode\":\"multiply\",\n",
        "            \"score_mode\":\"sum\"\n",
        "    }\n",
        "    }\n",
        "\n",
        "\n",
        "    response = es.search(\n",
        "        index=index_name,\n",
        "        body={\n",
        "            \"size\": 3,\n",
        "            \"query\": search_query,\n",
        "            \"_source\": [\"question\", \"answer\"]\n",
        "        }\n",
        "    )\n",
        "\n",
        "    if not response['hits']['hits']:\n",
        "        return \"نتیجهای یافت نشد\"\n",
        "\n",
        "    formatted_results = \"\"\n",
        "    for i, hit in enumerate(response['hits']['hits'], start=1):\n",
        "        result = hit['_source']\n",
        "        formatted_results += (\n",
        "            f\"Match {i}:\\n\"\n",
        "            f\"question: {result.get('question', '--')}\\n\"\n",
        "            f\"answer: {result.get('answer', '--')}\\n\\n\"\n",
        "        )\n",
        "\n",
        "    return formatted_results"
      ],
      "metadata": {
        "id": "re74eqjis03i"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def elastic_search5(query: str) -> str:\n",
        "    index_name = f\"dataset_5\"\n",
        "    query_embedding = model.encode(query, convert_to_tensor=False).tolist()\n",
        "    search_query = {\n",
        "        \"function_score\":{\n",
        "            \"query\": {\"multi_match\": {\"query\":query,\"fields\":[\"نام شهر\",\"معرفی \",\"آب و هوا\",\"دیدنی ها\",\"سوغات \",\"غذاهای محلی \",\"اقامت \",\"رستوران ها\",\"حمل‌ و نقل عمومی \", \"آداب و رسوم مردم \"]}},\n",
        "            \"functions\":[{\"script_score\": {\"script\": {\"source\": \"cosineSimilarity(params.query_vector, 'embedding') + 1.0\",\"params\": {\"query_vector\": query_embedding}}}}],\n",
        "            \"boost_mode\":\"multiply\",\n",
        "            \"score_mode\":\"sum\"\n",
        "    }\n",
        "    }\n",
        "    search_query = {\n",
        "        \"script_score\": {\n",
        "            \"query\": {\"match_all\": {}},\n",
        "            \"script\": {\n",
        "                \"source\": \"cosineSimilarity(params.query_vector, 'embedding') + 1.0\",\n",
        "                \"params\": {\"query_vector\": query_embedding}\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    response = es.search(\n",
        "        index=index_name,\n",
        "        body={\n",
        "            \"size\": 1,\n",
        "            \"query\": search_query,\n",
        "            \"_source\": [\"نام شهر\",\"معرفی \",\"آب و هوا\",\"دیدنی ها\",\"سوغات \",\n",
        "                        \"غذاهای محلی \",\"اقامت \",\"رستوران ها\",\"حمل‌ و نقل عمومی \", \"آداب و رسوم مردم \",\"راهنمای سفر \"]\n",
        "           }\n",
        "    )\n",
        "\n",
        "    if not response['hits']['hits']:\n",
        "        return \"نتیجهای یافت نشد\"\n",
        "\n",
        "    formatted_results = \"\"\n",
        "    for i, hit in enumerate(response['hits']['hits'], start=1):\n",
        "        result = hit['_source']\n",
        "        formatted_results += (\n",
        "            f\"Match {i}:\\n\"\n",
        "            f\"نام شهر: {result.get('نام شهر', '--')}\\n\"\n",
        "            f\"معرفی : {result.get('معرفی', '--')}\\n\\n\"\n",
        "            f\"آب و هوا {result.get('آب و هوا', '--')}\\n\\n\"\n",
        "            f\"دیدنی ها: {result.get('دیدنی ها', '--')}\\n\\n\"\n",
        "            f\"سوغات : {result.get('سوغات ', '--')}\\n\\n\"\n",
        "            f\"غذاهای محلی : {result.get('غذاهای محلی ', '--')}\\n\\n\"\n",
        "            f\"اقامت : {result.get('اقامت',' --')}\\n\\n\"\n",
        "            f\"رستوران ها: {result.get('رستوران ها', '--')}\\n\\n\"\n",
        "            f\"حمل‌ و نقل عمومی : {result.get('حمل‌ و نقل عمومی', '--')}\\n\\n\"\n",
        "            f\"آداب و رسوم مردم : {result.get('آداب و رسوم مردم', '--')}\\n\\n\"\n",
        "\n",
        "        )\n",
        "\n",
        "    return formatted_results"
      ],
      "metadata": {
        "id": "1RKO7-ba_UHx"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def elastic_search6(query: str) -> str:\n",
        "    index_name = f\"dataset_6\"\n",
        "    query_embedding = model.encode(query, convert_to_tensor=False).tolist()\n",
        "\n",
        "    search_query = {\n",
        "        \"function_score\":{\n",
        "            \"query\": {\"multi_match\": {\"query\":query,\"fields\":[\"question\", \"answer\"]}},\n",
        "            \"functions\":[{\"script_score\": {\"script\": {\"source\": \"cosineSimilarity(params.query_vector, 'embedding') + 1.0\",\"params\": {\"query_vector\": query_embedding}}}}],\n",
        "            \"boost_mode\":\"multiply\",\n",
        "            \"score_mode\":\"sum\"\n",
        "    }\n",
        "    }\n",
        "\n",
        "\n",
        "    response = es.search(\n",
        "        index=index_name,\n",
        "        body={\n",
        "            \"size\": 3,\n",
        "            \"query\": search_query,\n",
        "            \"_source\": [\"question\", \"answer\"]\n",
        "        }\n",
        "    )\n",
        "\n",
        "    if not response['hits']['hits']:\n",
        "        return \"نتیجهای یافت نشد\"\n",
        "\n",
        "    formatted_results = \"\"\n",
        "    for i, hit in enumerate(response['hits']['hits'], start=1):\n",
        "        result = hit['_source']\n",
        "        formatted_results += (\n",
        "            f\"Match {i}:\\n\"\n",
        "            f\"question: {result.get('question', '--')}\\n\"\n",
        "            f\"answer: {result.get('answer', '--')}\\n\\n\"\n",
        "        )\n",
        "\n",
        "    return formatted_results"
      ],
      "metadata": {
        "id": "u_GfIJ2ts2tr"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def elastic_search7(query: str) -> str:\n",
        "    index_name = f\"dataset_7\"\n",
        "    query_embedding = model.encode(query, convert_to_tensor=False).tolist()\n",
        "\n",
        "    search_query = {\n",
        "        \"function_score\":{\n",
        "            \"query\": {\"multi_match\": {\"query\":query,\"fields\":[\"question\", \"answer\"]}},\n",
        "            \"functions\":[{\"script_score\": {\"script\": {\"source\": \"cosineSimilarity(params.query_vector, 'embedding') + 1.0\",\"params\": {\"query_vector\": query_embedding}}}}],\n",
        "            \"boost_mode\":\"multiply\",\n",
        "            \"score_mode\":\"sum\"\n",
        "    }\n",
        "    }\n",
        "\n",
        "\n",
        "    response = es.search(\n",
        "        index=index_name,\n",
        "        body={\n",
        "            \"size\": 3,\n",
        "            \"query\": search_query,\n",
        "            \"_source\": [\"question\", \"answer\"]\n",
        "        }\n",
        "    )\n",
        "\n",
        "    if not response['hits']['hits']:\n",
        "        return \"نتیجهای یافت نشد\"\n",
        "\n",
        "    formatted_results = \"\"\n",
        "    for i, hit in enumerate(response['hits']['hits'], start=1):\n",
        "        result = hit['_source']\n",
        "        formatted_results += (\n",
        "            f\"Match {i}:\\n\"\n",
        "            f\"question: {result.get('question', '--')}\\n\"\n",
        "            f\"answer: {result.get('answer', '--')}\\n\\n\"\n",
        "        )\n",
        "\n",
        "    return formatted_results"
      ],
      "metadata": {
        "id": "ZLlWHYeZs3iK"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agentic RAG with Elasticsearch"
      ],
      "metadata": {
        "id": "Bc-80IZZd21J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"text-generation\", model=\"Qwen/Qwen2-7B-Instruct-AWQ\")\n"
      ],
      "metadata": {
        "id": "uQP9oMcKHFa4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "1c26622e604345c49a4fda5ba2cd5cd9",
            "149c69f751384846a7a570745a5a1b69",
            "fda4b11341754f98833a590bcfcd7436",
            "a744d366266440c8b501b39404f389b5",
            "4ec3daa28afe499e9bb22f58e85857e2",
            "7fb81564ae5d4418a170e4e145a4eb58",
            "85e1dada02094a65abdcefb34c2ba4e3",
            "bc02e003553344fbba4c8f5331e6e0e8",
            "eef12a6ec0784ac7812ee6cf0bb52dae",
            "55df26b3c4654062af4addf8587aa7a7",
            "b9d6abc791884dd381e0e442da571468"
          ]
        },
        "outputId": "0be7f90a-df60-46f0-c00d-aa3a6b4a8051"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You have loaded an AWQ model on CPU and have a CUDA device available, make sure to set your model on a GPU device in order to run your model.\n",
            "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1c26622e604345c49a4fda5ba2cd5cd9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_dataset(query: str) -> int:\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"\"\"\n",
        "            ### دستورالعمل:\n",
        "            فقط عدد مربوط به دسته را برگردانید:\n",
        "            1. سوالات  مربوط به اماکن تاریخی/فرهنگی ایران در هر شهری\n",
        "            2. سوغاتی\n",
        "            3. راهنمایی سفر به شهر های اصفهان ,مشهد، کیش ،رشت یا رامسر\n",
        "            4. سوال درمورد سفر به شهر های استانبول یاایروان\n",
        "            4. سوال درمورد سفر خارج از ایران به شرطی که سوال مربوط به  شهر استانبول یا ایروان نباشد\n",
        "            5.  سوال های مانند در موضوعات بالا قرار ندارند\n",
        "\n",
        "            مثال:\n",
        "\n",
        "\n",
        "            کاربر: آثار تخت جمشید؟ -> 1\n",
        "            کاربر: سوغاتی یزد چسیت؟ -> 2\n",
        "            کاربر: فصل مناسب برای سفر به شهر مشهد چیه؟ -> 3\n",
        "            کاربر: آیا ویزای شینگن برای سفر ضروری است؟ -> 4\n",
        "            کاربر: چرا باید به شهر استانبول سفر کرد پاریس رو پیشنهاد میدی یا استانبول رو\" -> 4\n",
        "            کاربر: چطور به فضا سفر کنم یا تیم فوتبال رئال مادرید در کدوم شهر است؟ -> 5\n",
        "            \"\"\"\n",
        "        },\n",
        "        {\"role\": \"user\", \"content\": query}\n",
        "    ]\n",
        "\n",
        "    response = classifier(\n",
        "        messages,\n",
        "        max_new_tokens=1,\n",
        "        top_p=0.1,\n",
        "        num_return_sequences=1,\n",
        "        pad_token_id=classifier.tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "    answer = response[0]['generated_text'][-1]['content'].strip()\n",
        "\n",
        "    try:\n",
        "        return int(answer)\n",
        "    except ValueError:\n",
        "        import re\n",
        "        match = re.search(r'\\d', answer)\n",
        "        return int(match.group()) if match else 0\n",
        "\n",
        "def generate_answer(context: str, question: str,dataset_num:int) -> str:\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": f\" با استفاده از متن زیر به سوال پاسخ دهید ممکن است متن اطلاعات زیادی داشته باشد فقط به سوال بصورت کوتاه و دقیق بر اساس متن پاسخ بده:\\n{context}\"\n",
        "        },\n",
        "        {\"role\": \"user\", \"content\": question}\n",
        "    ]\n",
        "\n",
        "    response = classifier(\n",
        "        messages,\n",
        "        max_new_tokens=450,\n",
        "        temperature=0.7,\n",
        "        pad_token_id=classifier.tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "    return response[0]['generated_text'][-1]['content']\n",
        "\n",
        "\n",
        "\n",
        "def generate_answer1(context: str,context2: str, question: str,dataset_num:int) -> str:\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": f\"  با استفاده از متن زیر به سوال پاسخ دهید ممکن است متن اطلاعات زیادی داشته باشد فقط به سوال بصورت کوتاه و دقیق بر اساس متن پاسخ بده:\\n{context}\\n{context2}.\"\n",
        "        },\n",
        "        {\"role\": \"user\", \"content\": question}\n",
        "    ]\n",
        "\n",
        "    response = classifier(\n",
        "        messages,\n",
        "        max_new_tokens=450,\n",
        "        temperature=0.7,\n",
        "        pad_token_id=classifier.tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "    return response[0]['generated_text'][-1]['content']\n",
        "\n",
        "def full_pipeline(user_query: str) -> str:\n",
        "    dataset_num = classify_dataset(user_query)\n",
        "    print(f\"\\n Dataset detected: {dataset_num}\")\n",
        "    print(f\"\\n{user_query}\")\n",
        "    if dataset_num==1:\n",
        "      try:\n",
        "          context1 = elastic_search1(user_query)\n",
        "          context2 = elastic_search2(user_query)\n",
        "          contexts = [context1, context2]\n",
        "          #print(f\"Context found: {context1[:100]}...\")\n",
        "          #print(f\"Context2 found: {context2[:100]}...\")\n",
        "          final_answer = generate_answer1(context1 ,context2, user_query,dataset_num)\n",
        "      except Exception as e:\n",
        "\n",
        "          return {\"question\": user_query,\"contexts\": [],\"answer\": f\"خطا در پردازش: {str(e)}\"}\n",
        "\n",
        "    elif dataset_num==2:\n",
        "      try:\n",
        "          context3 = elastic_search3(user_query)\n",
        "          context4 = elastic_search4(user_query)\n",
        "          contexts = [context3, context4]\n",
        "          #print(f\"Context found: {context3[:100]}...\")\n",
        "          #print(f\"Context2 found: {context4[:100]}...\")\n",
        "          final_answer = generate_answer1(context3 ,context4, user_query,dataset_num)\n",
        "      except Exception as e:\n",
        "\n",
        "          return {\"question\": user_query,\"contexts\": [],\"answer\": f\"خطا در پردازش: {str(e)}\"}\n",
        "\n",
        "    elif dataset_num==3:\n",
        "      try:\n",
        "          context5 = elastic_search5(user_query)\n",
        "          contexts = [context5]\n",
        "          #print(f\"Context found: {context5[:100]}...\")\n",
        "          final_answer = generate_answer(context5, user_query,dataset_num)\n",
        "      except Exception as e:\n",
        "\n",
        "          return {\"question\": user_query,\"contexts\": [],\"answer\": f\"خطا در پردازش: {str(e)}\"}\n",
        "\n",
        "\n",
        "    elif dataset_num==4 :\n",
        "      try:\n",
        "          context6 = elastic_search6(user_query)\n",
        "          context7 = elastic_search7(user_query)\n",
        "          contexts = [context6, context7]\n",
        "          #print(f\"Context found: {context6[:100]}...\")\n",
        "          #print(f\"Context2 found: {context7[:100]}...\")\n",
        "          final_answer = generate_answer1(context6 ,context6, user_query,dataset_num)\n",
        "      except Exception as e:\n",
        "\n",
        "            return {\"question\": user_query,\"contexts\": [],\"answer\": f\"خطا در پردازش: {str(e)}\"}\n",
        "    else:\n",
        "        print(\"\\n اطلاعات کافی برای پاسخ به این سوال را ندارم\")\n",
        "        print(\"-------------------------------------------------------------------\\n\")\n",
        "\n",
        "        return {\"query\": user_query, \"contexts\": [], \"answer\": \"اطلاعات کافی برای پاسخ به این سوال را ندارم\"}\n",
        "\n",
        "\n",
        "    return { \"question\": user_query,\"contexts\": contexts,\"answer\": final_answer.content if hasattr(final_answer, 'content') else str(final_answer)}\n",
        "\n"
      ],
      "metadata": {
        "id": "t2WyGwOvkBR9"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_queries = [\n",
        "    (\"ایا نقش جهان در شیراز است اگر نیست ادرسش کجاست؟\"),\n",
        "    (\"شیرینی معروف یزد چیه؟\"),\n",
        "    (\"تخت سلیمان مربوط به کدام دوره است؟\"),\n",
        "    (\"ایا کلیسای نوتردام از مهم‌ترین دیدنی‌های پاریس هست؟\"),\n",
        "    (\"چرا باید به شهر استانبول سفر کرد لندن رو پیشنهاد میدی یا استانبول رو؟\"),\n",
        "    (\"مکان های تفریحی برای سفر به شهر رشت رو بگو؟\"),\n",
        "    (\"سوغاتی مشهد چیست؟\"),\n",
        "    (\"چه برای کاری روز های گرم تابستان مناسب است؟\"),\n",
        "    (\"آثار تخت جمشید درکجا قرار دارد\"),\n",
        "]\n",
        "\n",
        "for query in test_queries:\n",
        "    answer=full_pipeline(query)\n",
        "    print(answer[\"answer\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IejI-VgVkmRH",
        "outputId": "fafe52c8-115f-42ad-8f47-1de4fe262c9b"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Dataset detected: 1\n",
            "\n",
            "ایا نقش جهان در شیراز است اگر نیست ادرسش کجاست؟\n",
            "نقش جهان در شهر اصفهان و نه شیراز قرار دارد. ادرس میدان نقش جهان در ایران، استان اصفهان، اصفهان است.\n",
            "\n",
            " Dataset detected: 2\n",
            "\n",
            "شیرینی معروف یزد چیه؟\n",
            "شیرینی معروف یزد \"قطاب\" است.\n",
            "\n",
            " Dataset detected: 1\n",
            "\n",
            "تخت سلیمان مربوط به کدام دوره است؟\n",
            "تخت سلیمان مربوط به دوره‌های مختلف تاریخی شامل اشکانی، ساسانی و ایلخانی است.\n",
            "\n",
            " Dataset detected: 4\n",
            "\n",
            "ایا کلیسای نوتردام از مهم‌ترین دیدنی‌های پاریس هست؟\n",
            "بله، کلیسای نوتردام یکی از مهم‌ترین دیدنی‌های پاریس است.\n",
            "\n",
            " Dataset detected: 4\n",
            "\n",
            "چرا باید به شهر استانبول سفر کرد لندن رو پیشنهاد میدی یا استانبول رو؟\n",
            "این بستگی به علت و مزیت شخصی شما دارد. لندن و استانبول دو شهر بزرگ و جذاب با دیدگاه های گوناگون هستند. لندن برای دانشجویان و محبوب هنرهای زیبا جذاب است، در حالی که استانبول برای افرادی که علاقه مند به تجربه های تاریخی و ثقافی هستند جذاب است. استانبول به عنوان یک رابطه بین شرق و غرب، دیدگاه های گوناگونی از فرهنگ، معماری و تاریخ را ارائه می دهد. لندن به عنوان مرکز فرهنگ و علمی جهان شناخته شده است و یکی از بهترین مراکز تفریح و سرگرمی ها را ارائه می دهد. بنابراین، تصمیم به سفر به یکی از این شهرها بستگی به علاقه و دلخواه شما دارد.\n",
            "\n",
            " Dataset detected: 3\n",
            "\n",
            "مکان های تفریحی برای سفر به شهر رشت رو بگو؟\n",
            "شهر رامسر دارای چندین مکان تفریحی است که می توانید در سفر به آنجا به آنها مراجعه کنید:\n",
            "\n",
            "1. ساحل زیبای خزر: جاذبه اصلی رامسر و جایی است که می توانید امواج خزر را تماشا کنید و خستگی کار و درس را از بدن خود بیرون بیاورید.\n",
            "\n",
            "2. تله کابین: تله کابین زیبای رامسر که به ساحل دریا و جنگل‌های کوهستانی شهر رامسر متصل می شود. \n",
            "\n",
            "3. کاخ مرمر: کاخ مرمر در باغی زیبا واقع شده و علاوه بر شکوه معماری، تابلوها و اشیای نفیسی را به تماشا گذاشته است.\n",
            "\n",
            "4. موزه مردم شناسی: این موزه در 5 کیلومتری شهر واقع شده و دیدنی دیگری است که به سفر شما می تواند اضافه شود.\n",
            "\n",
            "5. آبشار سیاسرت، قلعه مارکوه، غار یاغی لوکا و آبشار ایج: این جاهای دیدنی دیگری در منطقه رامسر هستند که می توانید به آنها مراجعه کنید.\n",
            "\n",
            "6. جواهرده: اگر زمان کافی دارید، به این شهر نزدیک شوید و از زیبایی‌های آن خاطره بسازید.\n",
            "\n",
            "لطفاً توجه داشته باشید که اطلاعات بالا شامل مکان های تفری\n",
            "\n",
            " Dataset detected: 2\n",
            "\n",
            "سوغاتی مشهد چیست؟\n",
            "سوغاتی مشهد، به زعفران اشاره دارد که مشهد به عنوان بهترین شهر برای خرید زعفران در ایران شناخته می‌شود.\n",
            "\n",
            " Dataset detected: 5\n",
            "\n",
            "چه برای کاری روز های گرم تابستان مناسب است؟\n",
            "\n",
            " اطلاعات کافی برای پاسخ به این سوال را ندارم\n",
            "-------------------------------------------------------------------\n",
            "\n",
            "اطلاعات کافی برای پاسخ به این سوال را ندارم\n",
            "\n",
            " Dataset detected: 1\n",
            "\n",
            "آثار تخت جمشید درکجا قرار دارد\n",
            "آثار تخت جمشید در استان فارس، شهرستان مرودشت، ایران قرار دارد. این مکان کیلومتری شمال شرق مرودشت است.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "_vpbR8RMHNqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_answer3(question: str) -> str:\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": f\"به سوال جواب بده\"\n",
        "        },\n",
        "        {\"role\": \"user\", \"content\": question}\n",
        "    ]\n",
        "\n",
        "    response = classifier(\n",
        "        messages,\n",
        "        max_new_tokens=150,\n",
        "        temperature=0.7,\n",
        "        pad_token_id=classifier.tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "    return response[0]['generated_text'][-1]['content']\n",
        "test_queries = [\n",
        "    (\"ایا نقش جهان در شیراز است اگر نیست ادرسش کجاست؟\"),\n",
        "    (\"شیرینی معروف یزد چیه؟\"),\n",
        "    (\"تخت سلیمان مربوط به کدام دوره است؟\"),\n",
        "    (\"ایا کلیسای نوتردام از مهم‌ترین دیدنی‌های پاریس هست؟\"),\n",
        "    (\"چرا باید به شهر استانبول سفر کرد لندن رو پیشنهاد میدی یا استانبول رو؟\"),\n",
        "    (\"مکان های تفریحی برای سفر به شهر رشت رو بگو؟\"),\n",
        "    (\"سوغاتی مشهد چیست؟\"),\n",
        "    (\"چه برای کاری روز های گرم تابستان مناسب است؟\"),\n",
        "    (\"آثار تخت جمشید درکجا قرار دارد\"),\n",
        "]\n",
        "\n",
        "for query in test_queries:\n",
        "    answer=generate_answer3(query)\n",
        "    print(f\"\\n {answer}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTUs-uAMIzCl",
        "outputId": "65a8ad2a-d27b-4c54-a3c0-a66d178d1184"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " نقشه جهان در شیراز، ایران در محوطه بازار گلستان واقع شده است. اگر برای نقشه جهان به دنبال یک مکان خاص هستید، ممکن است بهتر باشد برای محل دقیق تر آن مراجعه کنید. به طور کلی، نقشه جهان یک مکان تاریخی و دینی است که در میان شهر شیراز قرار دارد.\n",
            "\n",
            "\n",
            " شیرینی معروف در یزد به \"شیرینی سعیدی\" یا \"شیرینی نوری\" می‌گویند. این دو شیرینی که در یزد قرار دارند، به خاطر طعم و فن آهنگی خود شهرت دارند و گاهی برای سالن های گردشگری و بازار محلی یزد، تولید می شوند.\n",
            "\n",
            "\n",
            " تخت سلیمان، که اغلب به عنوان یک عنصر داستانی در کتاب مقدس ذکر می شود، به دوران پادشاه سلیمان در عهد قدیم در ایران مربوط می شود. این دوران تقریباً بین سال ها 960 و 923 قبل از میلاد می روند.\n",
            "\n",
            "\n",
            " بله، کلیسای نوتردام یکی از مهم‌ترین دیدنی‌های پاریس است. این کلیسا به عنوان یکی از معماری‌های برجستهٔ میانه‌ای در فرانسه شناخته می‌شود و برای بسیاری از گردشگران و علاقه‌مندان به تاریخ و معماری یکی از نقاط زیارت اصلی است.\n",
            "\n",
            "\n",
            " در این قسمت می توان از دو شهر، استانبول و لندن، برای سفر انتخاب کرد و هر دو شهر دارای مزایای خود هستند:\n",
            "\n",
            "لندن: \n",
            "\n",
            "1. تاریخ: لندن یکی از شهرهای قدیمی و ثروتمند تاریخی در جهان است. بازمانده های تاریخی بزرگی مانند برج ویتنی، گورستان سن پترس، موزه های ملی و بیش از ۱�\n",
            "\n",
            "\n",
            " شهر رشت در استان گلستان کشور ایران، با داشتن زیبایی های طبیعی و فرهنگی متنوع، چندین مکان تفریحی دارد که می توانید آنها را در سفر خود از آنها استفاده کنید:\n",
            "\n",
            "1. پارک ملی خلخال: این پارک ملی با دیدنی های طبیعی فوق العاده و حیوانات محلی، به عنوان یک مکان تفریحی بسیار مناسب است\n",
            "\n",
            "\n",
            " سoghate Meshed به معنای مسجد و مناطق تاریخی و فرهنگی در شهر مشهد، که مکان‌های دینی، تاریخی و هنری مطرح هستند، است. مشهد، یکی از شهرهای قدیمی ایران است که به خاطر مکان قرار دادن مسجد شیعه نجفی، یکی از مکان‌های مقدس برای مسلمانان شیعه، بسیار شهرت دارد. این شهر به عنوان دو\n",
            "\n",
            "\n",
            " برای کاری روز های گرم تابستان، به شما پیشنهاد می‌کنم از دستگاه هایی مثل ماکینه های یخ، ماکینه های چای یا ماکینه های چای گرم استفاده کنید تا می‌توانید با خودتان در آرامی و با دقت برداشت کرده و تهیه کرده باشید. این کار به شما کمک می‌کند تا در هوا گرم تابستان بدون فشار و در حالی\n",
            "\n",
            "\n",
            " تخت جمشید، یکی از شهرهای قدیمی و تاریخی ایران است که به عنوان یکی از مراکز مهم فرهنگ و ادبیات دوره هخامنشی شناخته می‌شود. اما به چهار تخت جمشید می‌گویند که هر یک در چهار ناحیه متفاوت ایران قرار دارد:\n",
            "\n",
            "1. تخت جمشید شرقی: در استان خراسان رضوی\n",
            "2. تخت جمشید غربی:\n",
            "\n"
          ]
        }
      ]
    }
  ]
}